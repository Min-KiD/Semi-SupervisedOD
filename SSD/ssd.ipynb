{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2bd683",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-29T16:30:48.748765Z",
     "iopub.status.busy": "2024-05-29T16:30:48.748183Z",
     "iopub.status.idle": "2024-05-29T16:30:49.563150Z",
     "shell.execute_reply": "2024-05-29T16:30:49.562316Z"
    },
    "papermill": {
     "duration": 0.822356,
     "end_time": "2024-05-29T16:30:49.565625",
     "exception": false,
     "start_time": "2024-05-29T16:30:48.743269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaf9aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:30:49.574437Z",
     "iopub.status.busy": "2024-05-29T16:30:49.573788Z",
     "iopub.status.idle": "2024-05-29T16:31:03.036094Z",
     "shell.execute_reply": "2024-05-29T16:31:03.035177Z"
    },
    "papermill": {
     "duration": 13.468971,
     "end_time": "2024-05-29T16:31:03.038353",
     "exception": false,
     "start_time": "2024-05-29T16:30:49.569382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac1d6a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:31:03.048121Z",
     "iopub.status.busy": "2024-05-29T16:31:03.047469Z",
     "iopub.status.idle": "2024-05-29T16:31:09.902601Z",
     "shell.execute_reply": "2024-05-29T16:31:09.901648Z"
    },
    "papermill": {
     "duration": 6.862685,
     "end_time": "2024-05-29T16:31:09.905079",
     "exception": false,
     "start_time": "2024-05-29T16:31:03.042394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class COCODataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        coco_annotations = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.coco.imgs[img_id]['file_name'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for annotation in coco_annotations:\n",
    "            x, y, w, h = annotation['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(annotation['category_id'])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        if self.transform:\n",
    "            image, target = self.transform(image, target)\n",
    "\n",
    "        return image, target, img_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        return image, target\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, flip_prob):\n",
    "        self.flip_prob = flip_prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if torch.rand(1) < self.flip_prob:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            bbox = target[\"boxes\"]\n",
    "            bbox[:, [0, 2]] = image.size(2) - bbox[:, [2, 0]]\n",
    "            target[\"boxes\"] = bbox\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecccca47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:31:09.914303Z",
     "iopub.status.busy": "2024-05-29T16:31:09.913891Z",
     "iopub.status.idle": "2024-05-29T16:31:10.204290Z",
     "shell.execute_reply": "2024-05-29T16:31:10.203244Z"
    },
    "papermill": {
     "duration": 0.297598,
     "end_time": "2024-05-29T16:31:10.206693",
     "exception": false,
     "start_time": "2024-05-29T16:31:09.909095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "    \n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(ToTensor())\n",
    "    if train:\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "    return Compose(transforms)\n",
    "\n",
    "train_dataset = COCODataset('/kaggle/input/coco-2017-dataset/coco2017/train2017',\n",
    "                            '/kaggle/input/semis-od-coco-10/instances_train2017_labeled.json',\n",
    "                            transform=get_transform(train=True))\n",
    "\n",
    "val_dataset = COCODataset('/kaggle/input/coco-2017-dataset/coco2017/train2017',\n",
    "                          '/kaggle/input/semis-od-coco-10/instances_val2017.json',\n",
    "                          transform=get_transform(train=False))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb1fa68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:31:10.216199Z",
     "iopub.status.busy": "2024-05-29T16:31:10.215879Z",
     "iopub.status.idle": "2024-05-29T16:31:14.618785Z",
     "shell.execute_reply": "2024-05-29T16:31:14.617798Z"
    },
    "papermill": {
     "duration": 4.410269,
     "end_time": "2024-05-29T16:31:14.621129",
     "exception": false,
     "start_time": "2024-05-29T16:31:10.210860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
      "100%|██████████| 136M/136M [00:00<00:00, 163MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection import ssd300_vgg16\n",
    "\n",
    "model = ssd300_vgg16(pretrained=True)\n",
    "model.head.classification_head.num_classes = 9  # classes + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4658cccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:31:14.633062Z",
     "iopub.status.busy": "2024-05-29T16:31:14.632359Z",
     "iopub.status.idle": "2024-05-29T16:52:57.612101Z",
     "shell.execute_reply": "2024-05-29T16:52:57.610905Z"
    },
    "papermill": {
     "duration": 1302.988098,
     "end_time": "2024-05-29T16:52:57.614541",
     "exception": false,
     "start_time": "2024-05-29T16:31:14.626443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 loss: 5.501976142849839\n",
      "Epoch #2 loss: 4.462156831172475\n",
      "Epoch #3 loss: 3.963499833268729\n",
      "Epoch #4 loss: 3.664462779697619\n",
      "Epoch #5 loss: 3.37359775297823\n",
      "Epoch #6 loss: 3.0470558188812076\n",
      "Epoch #7 loss: 2.8047260757078205\n",
      "Epoch #8 loss: 2.668801750355994\n",
      "Epoch #9 loss: 2.4757013251209816\n",
      "Epoch #10 loss: 2.2748053694329067\n",
      "Epoch #11 loss: 2.1647346563506544\n",
      "Epoch #12 loss: 2.0198814994410466\n",
      "Epoch #13 loss: 1.8535105213087204\n",
      "Epoch #14 loss: 1.7774837058887147\n",
      "Epoch #15 loss: 1.6048018845201235\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for images, targets, image_ids in train_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        #print(loss_dict)\n",
    "        #print(loss_dict.values())\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        total_loss += losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch #{epoch + 1} loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'ssd_vgg16_coco.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344b59b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:52:57.628899Z",
     "iopub.status.busy": "2024-05-29T16:52:57.628568Z",
     "iopub.status.idle": "2024-05-29T16:52:57.634451Z",
     "shell.execute_reply": "2024-05-29T16:52:57.633760Z"
    },
    "papermill": {
     "duration": 0.015218,
     "end_time": "2024-05-29T16:52:57.636364",
     "exception": false,
     "start_time": "2024-05-29T16:52:57.621146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ecb694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:52:57.649831Z",
     "iopub.status.busy": "2024-05-29T16:52:57.649274Z",
     "iopub.status.idle": "2024-05-29T16:53:55.658699Z",
     "shell.execute_reply": "2024-05-29T16:53:55.657420Z"
    },
    "papermill": {
     "duration": 58.01844,
     "end_time": "2024-05-29T16:53:55.660858",
     "exception": false,
     "start_time": "2024-05-29T16:52:57.642418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=15.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in data_loader:\n",
    "            images = list(img.to(device) for img in images)\n",
    "            outputs = model(images)\n",
    "            for img_id, output in zip(image_ids, outputs):\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                scores = output['scores'].cpu().numpy()\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    result = {\n",
    "                        'image_id': img_id,\n",
    "                        'category_id': label,\n",
    "                        'bbox': [box[0], box[1], box[2] - box[0], box[3] - box[1]],\n",
    "                        'score': score\n",
    "                    }\n",
    "                    results.append(result)\n",
    "    return results\n",
    "\n",
    "results = evaluate_model(model, val_loader, device)\n",
    "\n",
    "# Load ground truth annotations\n",
    "coco_gt = COCO('/kaggle/input/semis-od-coco-10/instances_val2017.json')\n",
    "coco_dt = coco_gt.loadRes(results)\n",
    "\n",
    "# Initialize COCOeval\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f126c",
   "metadata": {
    "papermill": {
     "duration": 0.006407,
     "end_time": "2024-05-29T16:53:55.674108",
     "exception": false,
     "start_time": "2024-05-29T16:53:55.667701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4857582,
     "sourceId": 8206445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1392.904623,
   "end_time": "2024-05-29T16:53:58.703696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-29T16:30:45.799073",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
